{
 "metadata": {
  "name": "",
  "signature": "sha256:38a2a46f9eafa0a7e32fcc8d6ac43130369d0fd5cbde7f374c2653571bb966b7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Regression Investigation\n",
      "Investigate the method to inject custom loss function in sklearn module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib as mpt\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn\n",
      "import vincent\n",
      "\n",
      "import os\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load toy datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "\n",
      "DATA_PATH = os.getcwd() + '/data/'\n",
      "train_df = pd.read_csv(DATA_PATH + 'training.csv', header=0)\n",
      "new_df = pd.read_csv(DATA_PATH + 'validation.csv', header=0)\n",
      "train_df = train_df.set_index('propertyid')\n",
      "new_df = new_df.set_index('propertyid')\n",
      "\n",
      "## Unpack predictor and response\n",
      "X, y = train_df.drop(['transvalue'], axis=1), train_df['transvalue']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>transdate</th>\n",
        "      <th>transdate_previous</th>\n",
        "      <th>transvalue_previous</th>\n",
        "      <th>bathroomcnt</th>\n",
        "      <th>bedroomcnt</th>\n",
        "      <th>builtyear</th>\n",
        "      <th>finishedsquarefeet</th>\n",
        "      <th>lotsizesquarefeet</th>\n",
        "      <th>storycnt</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>usecode</th>\n",
        "      <th>censustract</th>\n",
        "      <th>viewtypeid</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>propertyid</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>48650729</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td> 12/16/1994</td>\n",
        "      <td> 129500</td>\n",
        "      <td> 2.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1964</td>\n",
        "      <td> 2110</td>\n",
        "      <td>  8413</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469470</td>\n",
        "      <td>-122282926</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  11/3/1998</td>\n",
        "      <td> 138000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  7/26/2002</td>\n",
        "      <td> 184000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650837</th>\n",
        "      <td> 11/29/2005</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 1.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1935</td>\n",
        "      <td> 1060</td>\n",
        "      <td> 39060</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469990</td>\n",
        "      <td>-122275028</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48651057</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td>  5/30/1995</td>\n",
        "      <td> 552000</td>\n",
        "      <td> 2.25</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1991</td>\n",
        "      <td> 5410</td>\n",
        "      <td> 15002</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47332382</td>\n",
        "      <td>-122355990</td>\n",
        "      <td> 9</td>\n",
        "      <td> 30100</td>\n",
        "      <td>  3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "             transdate transdate_previous  transvalue_previous  bathroomcnt  \\\n",
        "propertyid                                                                    \n",
        "48650729    11/16/2005         12/16/1994               129500         2.00   \n",
        "48650769     9/23/2005          11/3/1998               138000         0.75   \n",
        "48650769     9/23/2005          7/26/2002               184000         0.75   \n",
        "48650837    11/29/2005                NaN                  NaN         1.00   \n",
        "48651057    11/16/2005          5/30/1995               552000         2.25   \n",
        "\n",
        "            bedroomcnt  builtyear  finishedsquarefeet  lotsizesquarefeet  \\\n",
        "propertyid                                                                 \n",
        "48650729             3       1964                2110               8413   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650837             3       1935                1060              39060   \n",
        "48651057             4       1991                5410              15002   \n",
        "\n",
        "            storycnt  latitude  longitude  usecode  censustract  viewtypeid  \n",
        "propertyid                                                                   \n",
        "48650729           1  47469470 -122282926        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650837           1  47469990 -122275028        9        28200         NaN  \n",
        "48651057           1  47332382 -122355990        9        30100           3  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Data Prepration: Missing Data Handling, Categorical Variable Recoding"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def basic_prep(data, col):\n",
      "    \"\"\"\n",
      "    Data Preparation\n",
      "    Todos:\n",
      "       1. Make a copy of the original dataset but with categorical variables (development purpose only)\n",
      "       2. \n",
      "       \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    \n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def yTranformer(y, rev=False):\n",
      "    \"\"\"\n",
      "    Transform repsonse variable, np.log10()\n",
      "    * choose base=10 for its ease of interpration\n",
      "    * through, base=e could be faster\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y: vector-like, \n",
      "    rev: boolean,\n",
      "    Returns\n",
      "    -------\n",
      "    res: logorithm of y at base 10\n",
      "    \"\"\"\n",
      "    if not rev:\n",
      "        res = np.log10(y)\n",
      "    else:\n",
      "        res = 10 ** y\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Split train data into 2 subsets for training and testing\n",
      "Training set and testing set are splitted from data carrying known response value ('/data/training.csv'). \n",
      "* The testing set are utilized only for model assessment in order to estimate the generalization error of the selected model. \n",
      "* On other hand, training data will be used for model selection within either k-fold cross-validation or boostraping cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
      "## Restrucutre data\n",
      "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
      "y_train = pd.Series(y_train)\n",
      "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
      "y_test = pd.Series(y_test)\n",
      "print \"-------------------------------------------------------------------------------\"\n",
      "print \"#obs for train (for train + validation): {0}\".format(X_train.shape[0])\n",
      "print \"#obs for test (for generalization error estimation): {0}\".format(X_test.shape[0])\n",
      "print \"-------------------------------------------------------------------------------\"\n",
      "\n",
      "## Histogram to examine the goodness of reandom sampling:\n",
      "fig, axes = plt.subplots(figsize=(12,5))\n",
      "\n",
      "data1 = y_train.apply(lambda x: yTranformer(x))\n",
      "data2 = y_test.apply(lambda x: yTranformer(x))\n",
      "axes.hist(data1, bins=15, normed=True, color=\"#6495ED\", alpha=.5)\n",
      "axes.hist(data2, bins=15, normed=True, color=\"#F08080\", alpha=.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-------------------------------------------------------------------------------\n",
        "#obs for train (for train + validation): 2297\n",
        "#obs for test (for generalization error estimation): 256\n",
        "-------------------------------------------------------------------------------\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "(array([ 0.02020045,  0.        ,  0.02020045,  0.        ,  0.08080182,\n",
        "         1.49483366,  2.14124822,  1.0302232 ,  0.24240546,  0.08080182,\n",
        "         0.        ,  0.02020045,  0.        ,  0.02020045,  0.02020045]),\n",
        " array([ 4.34242268,  4.53579704,  4.7291714 ,  4.92254575,  5.11592011,\n",
        "         5.30929447,  5.50266883,  5.69604319,  5.88941754,  6.0827919 ,\n",
        "         6.27616626,  6.46954062,  6.66291498,  6.85628933,  7.04966369,\n",
        "         7.24303805]),\n",
        " <a list of 15 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAE7CAYAAADARXdcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10f3458d0>"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above histogram displays the distributions of log(transvalue) in train (in blue) and test (in red). In train data set, the samples seem to be more concentrated and covering a wider range in prices. \n",
      " * Concentration on mid-range could understimate generalization error, given a good learner;\n",
      " * Inclusion of units whose prices are beyond the coverage of trianing sample could provide fair view on the generalization of a model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "Index([u'transdate', u'transdate_previous', u'transvalue_previous', u'bathroomcnt', u'bedroomcnt', u'builtyear', u'finishedsquarefeet', u'lotsizesquarefeet', u'storycnt', u'latitude', u'longitude', u'usecode', u'censustract', u'viewtypeid'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "## Feature selection (manuallly for development purpose only) --------------\n",
      "predictor = ['bathroomcnt', 'bedroomcnt', 'finishedsquarefeet', 'lotsizesquarefeet', 'storycnt']\n",
      "## Missing Value Imputation ------------------------------------------------\n",
      "missing_handler = Imputer(strategy=\"mean\")\n",
      "missing_handler.fit(X_train[predictor])\n",
      "X_train[predictor] = missing_handler.transform(X_train[predictor])\n",
      "X_test[predictor] = missing_handler.transform(X_test[predictor])\n",
      "## Respoonse variable transformation ---------------------------------------\n",
      "y_train = y_train.apply(lambda x: yTranformer(x))\n",
      "y_test = y_test.apply(lambda x: yTranformer(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Ordinal Linear Regression\n",
      "#### 2-1. Fitting Linear Regression with training data, validation data, testing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create linear Regressor\n",
      "regr = linear_model.LinearRegression(normalize=True)\n",
      "regr.fit(X_train[predictor], y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=True)"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.intercept_, regr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "(0.72601480473623348,\n",
        " array([ -1.04316023e-03,  -1.93592927e-03,   1.37287159e-05,\n",
        "         -8.08524118e-09,   2.90416348e-03]))"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.score(X_train[predictor], y_train), regr.score(X_test[predictor], y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "(0.50744437263878561, 0.50165591634408613)"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_hat = regr.predict(X_train[predictor])\n",
      "y_test_hat = regr.predict(X_test[predictor])\n",
      "train_residuals = y_train_hat - y_train\n",
      "test_residuals = y_test_hat - y_test\n",
      "## Plot residuals vs. log(y)\n",
      "fig, axes = plt.subplots(figsize=(12, 12))\n",
      "\n",
      "axes.scatter(y_train, train_residuals, 'r')\n",
      "axes.scatter(y_test, test_residuals, 'b')\n",
      "axes.set_xlabel('y_hat(log)')\n",
      "axes.set_ylabel('log(y)')\n",
      "axes.set_title('Residuals(log) vs. Log(Transvalue)');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1105866d0>"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Decision-Tree-based Feature Selection "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "tree_clf = ExtraTreesClassifier()\n",
      "X_new = tree_clf.fit(X_train[predictor], y_train).transform(X_train[predictor])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_importance = pd.DataFrame(zip(predictor, tree_clf.feature_importances_), \n",
      "                                  columns = ['feature', 'tree_based_feature_importance'])\n",
      "feature_importance."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}