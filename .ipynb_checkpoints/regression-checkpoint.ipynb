{
 "metadata": {
  "name": "",
  "signature": "sha256:6fdcb65b32fd4153c5b03f66bbf70e311738ce2d7d162c03faeabb89b9c51eac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Regression Investigation\n",
      "Investigate the method to inject custom loss function in sklearn module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib as mpt\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn\n",
      "import vincent\n",
      "\n",
      "import os\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load toy datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "\n",
      "DATA_PATH = os.getcwd() + '/data/'\n",
      "train_df = pd.read_csv(DATA_PATH + 'training.csv', header=0)\n",
      "new_df = pd.read_csv(DATA_PATH + 'validation.csv', header=0)\n",
      "train_df = train_df.set_index('propertyid')\n",
      "new_df = new_df.set_index('propertyid')\n",
      "\n",
      "## Unpack predictor and response\n",
      "X, y = train_df.drop(['transvalue'], axis=1), train_df['transvalue']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>transdate</th>\n",
        "      <th>transdate_previous</th>\n",
        "      <th>transvalue_previous</th>\n",
        "      <th>bathroomcnt</th>\n",
        "      <th>bedroomcnt</th>\n",
        "      <th>builtyear</th>\n",
        "      <th>finishedsquarefeet</th>\n",
        "      <th>lotsizesquarefeet</th>\n",
        "      <th>storycnt</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>usecode</th>\n",
        "      <th>censustract</th>\n",
        "      <th>viewtypeid</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>propertyid</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>48650729</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td> 12/16/1994</td>\n",
        "      <td> 129500</td>\n",
        "      <td> 2.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1964</td>\n",
        "      <td> 2110</td>\n",
        "      <td>  8413</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469470</td>\n",
        "      <td>-122282926</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  11/3/1998</td>\n",
        "      <td> 138000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  7/26/2002</td>\n",
        "      <td> 184000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650837</th>\n",
        "      <td> 11/29/2005</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 1.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1935</td>\n",
        "      <td> 1060</td>\n",
        "      <td> 39060</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469990</td>\n",
        "      <td>-122275028</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48651057</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td>  5/30/1995</td>\n",
        "      <td> 552000</td>\n",
        "      <td> 2.25</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1991</td>\n",
        "      <td> 5410</td>\n",
        "      <td> 15002</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47332382</td>\n",
        "      <td>-122355990</td>\n",
        "      <td> 9</td>\n",
        "      <td> 30100</td>\n",
        "      <td>  3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "             transdate transdate_previous  transvalue_previous  bathroomcnt  \\\n",
        "propertyid                                                                    \n",
        "48650729    11/16/2005         12/16/1994               129500         2.00   \n",
        "48650769     9/23/2005          11/3/1998               138000         0.75   \n",
        "48650769     9/23/2005          7/26/2002               184000         0.75   \n",
        "48650837    11/29/2005                NaN                  NaN         1.00   \n",
        "48651057    11/16/2005          5/30/1995               552000         2.25   \n",
        "\n",
        "            bedroomcnt  builtyear  finishedsquarefeet  lotsizesquarefeet  \\\n",
        "propertyid                                                                 \n",
        "48650729             3       1964                2110               8413   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650837             3       1935                1060              39060   \n",
        "48651057             4       1991                5410              15002   \n",
        "\n",
        "            storycnt  latitude  longitude  usecode  censustract  viewtypeid  \n",
        "propertyid                                                                   \n",
        "48650729           1  47469470 -122282926        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650837           1  47469990 -122275028        9        28200         NaN  \n",
        "48651057           1  47332382 -122355990        9        30100           3  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Data Prepration: Missing Data Handling, Categorical Variable Recoding"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def basic_prep(data, col):\n",
      "    \"\"\"\n",
      "    Data Preparation\n",
      "    Todos:\n",
      "       1. Make a copy of the original dataset but with categorical variables (development purpose only)\n",
      "       2. \n",
      "       \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    \n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def yTranformer(y, rev=False):\n",
      "    \"\"\"\n",
      "    Transform repsonse variable, np.log10()\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y: array/vector-like, \n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res: logorithm of y at base 10\n",
      "    \"\"\"\n",
      "    log10_y = np.log10(y)\n",
      "    return log10_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Split Train Data into 2 subsets for Training and Testing\n",
      "Training set and testing set are splitted from data carrying known response value ('/data/training.csv'). \n",
      "* The testing set are utilized only for model assessment in order to estimate the generalization error of the selected model. \n",
      "* On other hand, training data will be used for model selection within either k-fold cross-validation or boostraping cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
      "## Restrucutre data\n",
      "X_train = pd.DataFrame(X_train)\n",
      "y_train = pd.Series(y_train)\n",
      "X_test = pd.DataFrame(X_test)\n",
      "y_test = pd.Series(y_test)\n",
      "print \"-----------------------------\"\n",
      "print \"#obs for train (for train + validation): {0}\".format(X_train.shape[0])\n",
      "print \"#obs for test (for generalization error estimation): {0}\".format(X_test.shape[0])\n",
      "## Histogram to examine the goodness of reandom sampling:\n",
      "data1 = y_train.apply(lambda x: yTranformer(x))\n",
      "data2 = y_test.apply(lambda x: yTranformer(x))\n",
      "max_data = np.r_[data1, data2].max()\n",
      "plt.hist(), bins=15, normed=True, color=\"#6495ED\", alpha=.5)\n",
      "plt.hist(, bins=15, normed=True, color=\"#F08080\", alpha=.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-----------------------------\n",
        "#obs for train (for train + validation): 2297\n",
        "#obs for test (for generalization error estimation): 256\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "(array([ 0.02020045,  0.        ,  0.02020045,  0.        ,  0.08080182,\n",
        "         1.49483366,  2.14124822,  1.0302232 ,  0.24240546,  0.08080182,\n",
        "         0.        ,  0.02020045,  0.        ,  0.02020045,  0.02020045]),\n",
        " array([ 4.34242268,  4.53579704,  4.7291714 ,  4.92254575,  5.11592011,\n",
        "         5.30929447,  5.50266883,  5.69604319,  5.88941754,  6.0827919 ,\n",
        "         6.27616626,  6.46954062,  6.66291498,  6.85628933,  7.04966369,\n",
        "         7.24303805]),\n",
        " <a list of 15 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEDCAYAAADQunSaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFR1JREFUeJzt3V1sZOd93/EvZzh8W3KX++ZtLa0iF9Zjx4ZrOA0kQUYc\nuRAKS0mUGxWRgMCwAySGGxVGABcoDBS58U2u6sqRDaWODQtN7aAWIguFhDRBAjspYMGyLCeN5Pyj\nyGpXG0v7wiGXw+Esh5zpBWclcsh5ITncnXn0/dyIc87/HP79ePY3Z845fA5IkiRJkiRJkiRJkiRJ\nkiS97Yx1W5lSOgs8DrwDaAJ/EBGPtNXcDXwbeKW16ImI+PzgW5Uk7dV4j/V14Hci4oWU0izwg5TS\nn0XES21134mI+w+nRUnSfhW6rYyI1yPihdbPFeAl4J27lHb9RiBJujF6Hcm/KaV0K/Ah4Nm2VU3g\nrpTSj4DzwGcj4sWBdShJ2reuR/LXtE7VfAv4TOuIfqvngbMR8UHgi8CTg21RkrRfPU+zpJRKwP8E\nnomIL/RR/xPgX0XEQqeaRqPRHBvzDI8k7cXYPoKz6+malNIY8IfAi50CPqV0BrgQEc2U0u3AWLeA\nbzXKxYvLe+11aJw+PTey/Y9y72D/N5r9j55e5+Q/DPw68DcppR+2ln0OuAUgIh4DHgA+nVJaB6rA\ng4fUqyRpj7qGfET8Nb3vwHkUeHSQTUmSBqOvC6+SpNFkyEtSxgx5ScqYIS9JGTPkJSljhrwkZcyQ\nl6SMGfKSlDFDXpIyZshLUsYMeUnKmCEvSRkz5CUpY4a8JGXMkJekjBnykpQxQ16SMmbIS1LGDHlJ\nypghL0kZM+QlKWOGvCRlzJCXpIwZ8pKUMUNekjJmyEtSxgx5ScrY+I1uQNqLRqPBwsLlgexrfv44\nhYLHOcqbIa+RUi6XWf7uXzI/O3ug/SxWKvCRj3LixMkBdSYNJ0NeI2d+dpYTR48eeD8bA+hFGnZ+\nV5WkjBnykpQxQ16SMuY5eQ2FRqPB4mK5Z12hUOdqbZXVUmnHuqmpKcbGxg6jPWlkGfIaCouLZZ5+\nboEjs/Nd6zbWV/mZy7B0tblteX2txm3vhOnp6cNsUxo5hryGxpHZeeaOnehas1EvMTE1xeSUYS71\no2vIp5TOAo8D7wCawB9ExCO71D0C3AtUgU9ExA8PoVdJ0h71uvBaB34nIt4P3An8dkrpZ7cWpJTu\nA94dEbcBvwV8+VA6lSTtWdeQj4jXI+KF1s8V4CXgnW1l9wNfb9U8C8ynlM4cQq+SpD3q+xbKlNKt\nwIeAZ9tW3QSc2/L6NeDmA3cmSTqwvi68ppRmgW8Bn2kd0bdrv2+tuUvNNqdPz/Xzq4fWKPc/jL0X\nCmvMzFQ5MjPRte7KEpTGi5RKxW3LGxsFZmZKTM9M9vX7VtcnmDo1x8mT138shnH898L+R0vPkE8p\nlYAngP8WEU/uUnIeOLvl9c2tZV1dvLjcb49D5/TpuZHtf1h7X1hYplptUCyt9aytr29Qr2+feaZe\nb1CtrtFsFjtstd1qdY3KpWUaje4fKoM2rOPfL/sfPV1P16SUxoA/BF6MiC90KHsK+Hir/k5gMSLe\nGGiXkqR96XUk/2Hg14G/SSlduy3yc8AtABHxWEQ8nVK6L6X0MrACfPLQupUk7UnXkI+Iv6aPi7MR\n8fDAOpIkDYwTlElSxgx5ScqYc9coC81mk9Vare/6Wm2VSnn7rJc+81U5MuSVhfpajVcvbDA90/NP\nNABYqsCP/6HB7NEGACuVRe77eXzmq7JjyCsbpYnJvmennFivM3v0eM9ZL6VR53dTScqYIS9JGTPk\nJSljhrwkZcyQl6SMGfKSlDFDXpIyZshLUsYMeUnKmCEvSRkz5CUpY4a8JGXMkJekjBnykpQxQ16S\nMmbIS1LGDHlJypghL0kZM+QlKWOGvCRlzJCXpIwZ8pKUMUNekjJmyEtSxgx5ScqYIS9JGTPkJSlj\nhrwkZcyQl6SMGfKSlLHxXgUppa8CvwRciIgP7LL+buDbwCutRU9ExOcH2aQkaX96hjzwNeCLwONd\nar4TEfcPpiVJ0qD0PF0TEX8FlHuUjQ2mHUnSIPVzJN9LE7grpfQj4Dzw2Yh4cQD7lSQd0CBC/nng\nbERUU0r3Ak8CaQD7VSYajQaLi92/DJbLZSpXGj33tbFe4UyzOajWpOwdOOQjYnnLz8+klL6UUjoR\nEQvdtjt9eu6gv/qGGuX+r3fvly9fZv25/8387GzHmvHVVT6wUGdiZabrvl678FM4doxSqbhtealU\npFAs7ljeSWm8yMxMiSMzEwBs1EucOjXDyZOHPzaj/N4B+x81Bw75lNIZNu+8aaaUbgfGegU8wMWL\ny71Khtbp03Mj2/+N6H1hYZnJwgTT41Odi8abzExOMjk13XVfczOz1OtN6vWNbcvr9Q0KjbEdyzup\nr29QrdYpltYAqFbrXLq0TKMx0df2+zXK7x2w/1HUzy2U3wB+ETiVUjoH/C5QAoiIx4AHgE+nlNaB\nKvDg4bUrSdqLniEfEQ/1WP8o8OjAOpIkDYx/8SpJGTPkJSljhrwkZcyQl6SMGfKSlDFDXpIyZshL\nUsYMeUnKmCEvSRkz5CUpY4a8JGXMkJekjBnykpQxQ16SMmbIS1LGDHlJypghL0kZM+QlKWOGvCRl\nzJCXpIwZ8pKUMUNekjJmyEtSxgx5ScqYIS9JGTPkJSljhrwkZcyQl6SMGfKSlDFDXpIyZshLUsYM\neUnKmCEvSRkz5CUpY4a8JGXMkJekjI33KkgpfRX4JeBCRHygQ80jwL1AFfhERPxwoF1KkvalZ8gD\nXwO+CDy+28qU0n3AuyPitpTSHcCXgTsH16I0eI1Gg8qV8puvK1fKlMv7/2I7P3+cQsEvxho+PUM+\nIv4qpXRrl5L7ga+3ap9NKc2nlM5ExBsD6lEauMrqCjctPsvJE6cAWKvVmF2H4tT0nve1WKnARz7K\niRMnB92mdGD9HMn3chNwbsvr14CbAUNeQ21uZpb52aMAXB0vcXxujOnpvYc8wMYgG5MGaFDfL8fa\nXjcHtF9J0gEM4kj+PHB2y+ubW8u6On16bgC/+sYZ5f6vd++Fwhq1mQlmjkx2rBkb26BUqlMqFXvu\nr1Qa21FXKhUpFIt9bQ8wXixu209jo8DMTInpmc49drK6PsHUqTlOnuxvXEf5vQP2P2oGEfJPAQ8D\n30wp3Qks9nM+/uLF5QH86hvj9Om5ke3/RvS+sLBMsbpGdfxqx5rV1TXq9SaFYu8TH/V6k3p9o23Z\nBoXG2I7lnaxvbFCn8GZ9vd6gWl2j2ezvQ2Jb79U1KpeWaTQmetaO8nsH7H8U9XML5TeAXwROpZTO\nAb8LlAAi4rGIeDqldF9K6WVgBfjkYTYsSepfP3fXPNRHzcODaUeSNEje2CtJGTPkJSljhrwkZcyQ\nl6SMGfKSlDFDXpIyZshLUsYMeUnKmCEvSRkz5CUpY4a8JGXMkJekjBnykpQxQ16SMmbIS1LGBvFk\nKGnkNZtNVmu1fW1bq61SKZeZnz9OoeBxk4aLIS8B9bUar17YYHpm78+gX6rA8y+U+bfHy5w4cfIQ\nupP2z5CXWkoTk0xOTe95u4n1OjNHjh1CR9LB+d1SkjJmyEtSxgx5ScqYIS9JGTPkJSlj3l2jgWg0\nGiwulnddVy6Xma2tsloqddx+tbYKTB5Sd9LblyGvgVhcLPP0cwscmZ3fsa5ypcF7L8PS1c73oK9U\nakxOFY15acAMeQ3Mkdl55o6d2HXdxNJU13vQ166uHlZb0tua5+QlKWOGvCRlzJCXpIwZ8pKUMUNe\nkjJmyEtSxgx5ScqYIS9JGTPkJSljhrwkZazntAYppY8BXwCKwFci4vfa1t8NfBt4pbXoiYj4/ID7\nlCTtQ9eQTykVgd8H7gHOA99PKT0VES+1lX4nIu4/pB4lSfvU63TN7cDLEfFqRNSBbwK/ukvd2MA7\nkyQdWK/TNTcB57a8fg24o62mCdyVUvoRm0f7n42IFwfXoiRpv3qFfOcJwN/yPHA2IqoppXuBJ4HU\na6PTp+f62PXwGuX+D6P3QmGNmZkqR2YmdqzbqJcojRcplYodty+VihSK3Wveqh3bUbeX7QHGi8Vt\n+9nr9tt+93iR6ZkSp07NcfJk77Ed5fcO2P+o6RXy54GzW16fZfNo/k0Rsbzl52dSSl9KKZ2IiIVu\nO754cbnb6qF2+vTcyPZ/WL0vLCxTrTYoltZ2rKtW69TXN6jXNzpuX69vUGiMda15q7a5o24v2wOs\nb2xQp/Bm/V633/a71zdYrda5dGmZRmPnh9xWo/zeAfsfRb1C/jngtpTSrcA/Ab8GPLS1IKV0BrgQ\nEc2U0u3AWK+AlyRdH10vvEbEOvAw8KfAi8AfR8RLKaVPpZQ+1Sp7APjblNILbN5q+eBhNixJ6l/P\n++Qj4hngmbZlj235+VHg0cG3Jkk6KP/iVZIyZshLUsYMeUnKmCEvSRkz5CUpY4a8JGXMkJekjBny\nkpQxQ16SMmbIS1LGDHlJypghL0kZM+QlKWOGvCRlzJCXpIwZ8pKUMUNekjLW88lQkrprNBqsLC9S\nLvc+ZioU1lhY6Pwg6fn54xQKHntpcAx56YAqqyvcunye4tgc9amprrWL0xPUV9d2X1dZoXHPxzh1\n6tRhtKm3KUNeGoDp8RJLq9Osjc12ras2CtTrk7uuu1ypMb60aMhroAx5aUBKE5NMTk13rykVKRQ3\nOqzr/i1A2g9P/klSxgx5ScqYIS9JGTPkJSljhrwkZcyQl6SMGfKSlDFDXpIyZshLUsb8i1dpSDSb\nTZaWFllYuLzvfTjBmdoZ8tKQqNdrfO/HNf5vrbGv7Vcqi9z383DixMkBd6ZRZsiro0ajweJiua/a\ncrlM5cru4VS5UqbZbA6ytSw1Gg04wDg1G03K5bf+//KoXmDIi85hXi6XWf/+95ifPdJzH8Vajfeu\nTDKxtHOCrn+68Dr1o/MwN5B2s1WpVXl39e+4abyyr+3XajVm16E4Nc1ipQIf+ahH9TLkBYuLZZ5+\nboEjs/PblleuNHjv1SOMlXqn88rKBkempjkye3THuisrnR+Soe3mpo8wv8sY9uPqeInjc2NMT29+\n0O4+16XebnqGfErpY8AXgCLwlYj4vV1qHgHuBarAJyLih4NuVIfryOw8c8dO7Fg+sTTVc/pcgLWr\nq4fRlqQD6nrCLqVUBH4f+BjwPuChlNLPttXcB7w7Im4Dfgv48iH1Kknao15H8rcDL0fEqwAppW8C\nvwq8tKXmfuDrABHxbEppPqV0JiLeOIR+B6JarbJarR5gDzUuX9o8b3psfp7x8YOf9drLRc6d227e\nenfNsWPHOl5w2+0Zo+VymWZzf6cINDyazSartRoAtdoqlfLe30/tF2vb35e9nlG71/3vx0H+rbT3\n32g0gDEKhbED9QTDe6G7VzrdBJzb8vo14I4+am4Ghjbk/9/z3+ef1/Z/emFtZoLx6hq1tTXeeN+/\n5KZbbz1wT4uLZZa/+5fMz3Z/fNxu6rVV3ni9Rqk0xXK1wvl33cHs0eO71s7MVKlWt98Fc+GnZY4e\nn9hX3xoe9bUar17YYHqmyVIFfvwPDWaP9n875vKVBT58W5njx99677RffO/2jFqAyckpxsZ2D8xe\nF4P7De9eNwR066E2M0Gx+lb/515/nanxcf7ZAR+5OMwXunuFfL/3c7WP6FDfL9coFrhUX3/z9RsX\nLrCw0P+RwcRkibWrddY3NnjtJ69x8y0/wwfe954D9bS0tMiRWo3aeHHP2147ertmZXmxQyVsrJdY\nrda3LatWlrh69Srrazv3c2zhEmtt+99NdWWJQqHIyi61C+XLTPX4ttNt+237WrzE+C5nGfvdvlNP\ne92+fV/N+iqF4njP7UulMer13f95LC0vUq/VmJq+sOce4K3/DWuNJsvVStf3wW4uv3GOb52rc2z+\nrWsz1coV3n9lldnlzTEvjV+lvr77B8dGfY1b3lFjusPDzGu1Gpdf/cm22zy3Wlpa5Lv/Z4mp6R7P\nyW3rqb2H99wCU31cR3q76BXy54GzW16fZfNIvVvNza1lHY11+piVJA1UrxNIzwG3pZRuTSlNAL8G\nPNVW8xTwcYCU0p3A4jCfj5ekt5OuIR8R68DDwJ8CLwJ/HBEvpZQ+lVL6VKvmaeCVlNLLwGPAvzvk\nniVJkiRJkiRJkiRpqBzqrYytaRGeA16LiF/ZZf1Qz3nTrf+U0t3At4FXWoueiIjPX98OO0spvQpc\nYXOeqnpE3L5LzdCOf6/+R2D854GvAO9n8+9GfiMivtdWM8zj37X/YR7/lNJ7gG9uWfQvgP8UEY+0\n1Q3d+PfT+17H/rBnofwMm3fl7JjGcOucNymlO9ic8+bOQ+5nrzr23/KdiLj/OvazF03g7ohY2G3l\nCIx/1/5bhnn8/wvwdEQ8kFIaB7b9eeYIjH/X/luGcvwj4u+BDwGklAps/t3On2ytGdbx76f3lr7H\n/tAmWkgp3Qzcx+bRwG7fGLbNeQPMp5TOHFY/e9VH/3RZPiy69TfU49/Sa3yHcvxTSseAX4iIr8Lm\nrcgRsdRWNrTj32f/MKTj3+Ye4B8j4lzb8qEd/y069Q57GPvDPJL/z8B/ADrNfDXsc9706r8J3JVS\n+hGbn7afjYgXr1dzfWgCf55S2gAei4j/2rZ+2Me/V//DPP7vAi6mlL4GfBD4AfCZiNg6K94wj38/\n/Q/z+G/1IPDfd1k+zON/Tafe9zT2h3Ikn1L6ZeBC6xxXt0+coZzzps/+nwfORsQHgS8CT16v/vr0\n4Yj4EJvnHH87pfQLu9QM5fi39Op/mMd/HPg54EsR8XPACvAfd6kb1vHvp/9hHn8AWn+l/yvA/+hQ\nMqzj36v3PY39YZ2uuQu4P6X0E+AbwL9OKT3eVrPnOW+uo579R8TytSObiHgGKKWUdj514waJiJ+2\n/nuRzXN67Rdeh3n8e/Y/5OP/GpsX67/fev0tNkNzq2Ee/579D/n4X3Mv8IPWe6jdMI8/dOl9r2N/\nKCEfEZ+LiLMR8S42v3L8RUR8vK1saOe86af/lNKZlNJY6+fbgbEeFwmvm5TSTEpprvXzEeDfAH/b\nVja0499P/8M8/hHxOnAupZRai+4B/q6tbGjHv5/+h3n8t3iIzYO03Qzt+Ld07H2vY3+9nvHabDV0\nbb6bxyLi6ZTSfa05b1aAT16nXvZjR//AA8CnU0rrbN6C9eCNa2+HM8CftP6NjgN/FBH/a4TGv2f/\nDPf4A/x74I9aX7v/EfiNERp/6NE/Qz7+rYODe4Df3LJsJMa/V+8M+dhLkiRJkiRJkiRJkiRJkiRJ\nkiRJ0r78fwmK/lhi/OcOAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10e245510>"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above histogram display the distributions of log(transvalue) in train (in blue) and test (in red). In train data set, the samples are more concentrated on the mid-range of price. And, the deviation from the  underestimate the generalization error. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(y_test).apply(lambda x: yTranformer(x))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "0     5.478566\n",
        "1     5.477121\n",
        "2     5.876016\n",
        "3     5.638489\n",
        "4     5.585461\n",
        "5     5.479935\n",
        "6     5.267172\n",
        "7     5.919078\n",
        "8     5.649530\n",
        "9     5.468273\n",
        "10    5.447158\n",
        "11    5.594393\n",
        "12    5.454845\n",
        "13    5.860338\n",
        "14    5.799341\n",
        "...\n",
        "241    5.618048\n",
        "242    5.734800\n",
        "243    5.230449\n",
        "244    5.579784\n",
        "245    6.173186\n",
        "246    5.579784\n",
        "247    5.638489\n",
        "248    5.673021\n",
        "249    5.667453\n",
        "250    5.720159\n",
        "251    5.469822\n",
        "252    5.860338\n",
        "253    5.612731\n",
        "254    5.648360\n",
        "255    5.414973\n",
        "Length: 256, dtype: float64"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Ordinal Linear Regression\n",
      "#### 2-1. Fitting Linear Regression with training data, validation data, testing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "#from sklearn.datasets.samples_geneartor import make_regression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create linear Regressor\n",
      "regr = linear_model.LinearRegression(normalize=True)\n",
      "regr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=True)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "array([ -1.07170557e-01,   4.63952195e-02,   2.08602395e-02,\n",
        "         2.68856140e+00,  -1.77957587e+01,   3.80475246e+00,\n",
        "         7.51061703e-04,  -1.47575880e+00,   3.05655038e-01,\n",
        "        -1.23293463e-02,  -9.53463555e-01,   9.39251272e-03,\n",
        "        -5.25466633e-01])"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}