{
 "metadata": {
  "name": "",
  "signature": "sha256:e32effa00a43ee6b549e8bb0ee2b64071f2e8fa6cda242d103b852ba2b479b48"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Regression Investigation\n",
      "Investigate the method to inject custom loss function in sklearn module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib as mpt\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn\n",
      "import vincent\n",
      "\n",
      "import os\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load toy datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "\n",
      "DATA_PATH = os.getcwd() + '/data/'\n",
      "train_df = pd.read_csv(DATA_PATH + 'training.csv', header=0)\n",
      "new_df = pd.read_csv(DATA_PATH + 'validation.csv', header=0)\n",
      "train_df = train_df.set_index('propertyid')\n",
      "new_df = new_df.set_index('propertyid')\n",
      "\n",
      "## Unpack predictor and response\n",
      "X, y = train_df.drop(['transvalue'], axis=1), train_df['transvalue']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>transdate</th>\n",
        "      <th>transdate_previous</th>\n",
        "      <th>transvalue_previous</th>\n",
        "      <th>bathroomcnt</th>\n",
        "      <th>bedroomcnt</th>\n",
        "      <th>builtyear</th>\n",
        "      <th>finishedsquarefeet</th>\n",
        "      <th>lotsizesquarefeet</th>\n",
        "      <th>storycnt</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>usecode</th>\n",
        "      <th>censustract</th>\n",
        "      <th>viewtypeid</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>propertyid</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>48650729</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td> 12/16/1994</td>\n",
        "      <td> 129500</td>\n",
        "      <td> 2.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1964</td>\n",
        "      <td> 2110</td>\n",
        "      <td>  8413</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469470</td>\n",
        "      <td>-122282926</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  11/3/1998</td>\n",
        "      <td> 138000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650769</th>\n",
        "      <td>  9/23/2005</td>\n",
        "      <td>  7/26/2002</td>\n",
        "      <td> 184000</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 1220</td>\n",
        "      <td> 16867</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47468266</td>\n",
        "      <td>-122283976</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48650837</th>\n",
        "      <td> 11/29/2005</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> 1.00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1935</td>\n",
        "      <td> 1060</td>\n",
        "      <td> 39060</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47469990</td>\n",
        "      <td>-122275028</td>\n",
        "      <td> 9</td>\n",
        "      <td> 28200</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48651057</th>\n",
        "      <td> 11/16/2005</td>\n",
        "      <td>  5/30/1995</td>\n",
        "      <td> 552000</td>\n",
        "      <td> 2.25</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1991</td>\n",
        "      <td> 5410</td>\n",
        "      <td> 15002</td>\n",
        "      <td> 1</td>\n",
        "      <td> 47332382</td>\n",
        "      <td>-122355990</td>\n",
        "      <td> 9</td>\n",
        "      <td> 30100</td>\n",
        "      <td>  3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "             transdate transdate_previous  transvalue_previous  bathroomcnt  \\\n",
        "propertyid                                                                    \n",
        "48650729    11/16/2005         12/16/1994               129500         2.00   \n",
        "48650769     9/23/2005          11/3/1998               138000         0.75   \n",
        "48650769     9/23/2005          7/26/2002               184000         0.75   \n",
        "48650837    11/29/2005                NaN                  NaN         1.00   \n",
        "48651057    11/16/2005          5/30/1995               552000         2.25   \n",
        "\n",
        "            bedroomcnt  builtyear  finishedsquarefeet  lotsizesquarefeet  \\\n",
        "propertyid                                                                 \n",
        "48650729             3       1964                2110               8413   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650769             2       1942                1220              16867   \n",
        "48650837             3       1935                1060              39060   \n",
        "48651057             4       1991                5410              15002   \n",
        "\n",
        "            storycnt  latitude  longitude  usecode  censustract  viewtypeid  \n",
        "propertyid                                                                   \n",
        "48650729           1  47469470 -122282926        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650769           1  47468266 -122283976        9        28200         NaN  \n",
        "48650837           1  47469990 -122275028        9        28200         NaN  \n",
        "48651057           1  47332382 -122355990        9        30100           3  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Data Prepration: Missing Data Handling, Categorical Variable Recoding"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def basic_prep(data, col):\n",
      "    \"\"\"\n",
      "    Data Preparation\n",
      "    Todos:\n",
      "       1. Make a copy of the original dataset but with categorical variables (development purpose only)\n",
      "       2. \n",
      "       \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    \n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def yTranformer(y, rev=False):\n",
      "    \"\"\"\n",
      "    Transform repsonse variable, np.log10()\n",
      "    * choose base=10 for its ease of interpration\n",
      "    * through, base=e could be faster\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y: vector-like, \n",
      "    rev: boolean,\n",
      "    Returns\n",
      "    -------\n",
      "    res: logorithm of y at base 10\n",
      "    \"\"\"\n",
      "    if not rev:\n",
      "        res = np.log10(y)\n",
      "    else:\n",
      "        res = 10 ** y\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Split train data into 2 subsets for training and testing\n",
      "Training set and testing set are splitted from data carrying known response value ('/data/training.csv'). \n",
      "* The testing set are utilized only for model assessment in order to estimate the generalization error of the selected model. \n",
      "* On other hand, training data will be used for model selection within either k-fold cross-validation or boostraping cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
      "## Restrucutre data\n",
      "X_train = pd.DataFrame(X_train, columns = X.columns)\n",
      "y_train = pd.Series(y_train)\n",
      "X_test = pd.DataFrame(X_test, columns = X.columns)\n",
      "y_test = pd.Series(y_test)\n",
      "print \"-------------------------------------------------------------------------------\"\n",
      "print \"#obs for train (for train + validation): {0}\".format(X_train.shape[0])\n",
      "print \"#obs for test (for generalization error estimation): {0}\".format(X_test.shape[0])\n",
      "print \"-------------------------------------------------------------------------------\"\n",
      "\n",
      "## Histogram to examine the goodness of reandom sampling:\n",
      "fig, axes = plt.subplots(figsize=(12,5))\n",
      "\n",
      "data1 = y_train.apply(lambda x: yTranformer(x))\n",
      "data2 = y_test.apply(lambda x: yTranformer(x))\n",
      "axes.hist(data1, bins=15, normed=True, color=\"#6495ED\", alpha=.5)\n",
      "axes.hist(data2, bins=15, normed=True, color=\"#F08080\", alpha=.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-------------------------------------------------------------------------------\n",
        "#obs for train (for train + validation): 2297\n",
        "#obs for test (for generalization error estimation): 256\n",
        "-------------------------------------------------------------------------------\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "(array([ 0.02020045,  0.        ,  0.02020045,  0.        ,  0.08080182,\n",
        "         1.49483366,  2.14124822,  1.0302232 ,  0.24240546,  0.08080182,\n",
        "         0.        ,  0.02020045,  0.        ,  0.02020045,  0.02020045]),\n",
        " array([ 4.34242268,  4.53579704,  4.7291714 ,  4.92254575,  5.11592011,\n",
        "         5.30929447,  5.50266883,  5.69604319,  5.88941754,  6.0827919 ,\n",
        "         6.27616626,  6.46954062,  6.66291498,  6.85628933,  7.04966369,\n",
        "         7.24303805]),\n",
        " <a list of 15 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAE7CAYAAADARXdcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10f3458d0>"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above histogram displays the distributions of log(transvalue) in train (in blue) and test (in red). In train data set, the samples seem to be more concentrated and covering a wider range in prices. \n",
      " * Concentration on mid-range could understimate generalization error, given a good learner;\n",
      " * Inclusion of units whose prices are beyond the coverage of trianing sample could provide fair view on the generalization of a model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "Index([u'transdate', u'transdate_previous', u'transvalue_previous', u'bathroomcnt', u'bedroomcnt', u'builtyear', u'finishedsquarefeet', u'lotsizesquarefeet', u'storycnt', u'latitude', u'longitude', u'usecode', u'censustract', u'viewtypeid'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "## Feature selection (manuallly for development purpose only) --------------\n",
      "predictor = ['bathroomcnt', 'bedroomcnt', 'finishedsquarefeet', 'lotsizesquarefeet', 'storycnt']\n",
      "## Missing Value Imputation ------------------------------------------------\n",
      "missing_handler = Imputer(strategy=\"mean\")\n",
      "missing_handler.fit(X_train[predictor])\n",
      "X_train[predictor] = missing_handler.transform(X_train[predictor])\n",
      "X_test[predictor] = missing_handler.transform(X_test[predictor])\n",
      "## Respoonse variable transformation ---------------------------------------\n",
      "y_train = y_train.apply(lambda x: yTranformer(x))\n",
      "y_test = y_test.apply(lambda x: yTranformer(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Ordinal Linear Regression\n",
      "#### 2-1. Fitting Linear Regression with training data, validation data, testing data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create linear Regressor\n",
      "regr = linear_model.LinearRegression(normalize=True)\n",
      "regr.fit(X_train[predictor], y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=True)"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.intercept_, regr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "(0.72601480473623348,\n",
        " array([ -1.04316023e-03,  -1.93592927e-03,   1.37287159e-05,\n",
        "         -8.08524118e-09,   2.90416348e-03]))"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.score(X_train[predictor], y_train), regr.score(X_test[predictor], y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "(0.50744437263878561, 0.50165591634408613)"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_hat = regr.predict(X_train[predictor])\n",
      "y_test_hat = regr.predict(X_test[predictor])\n",
      "train_residuals = y_train_hat - y_train\n",
      "test_residuals = y_test_hat - y_test\n",
      "## Plot residuals vs. log(y)\n",
      "fig, axes = plt.subplots(figsize=(12, 12))\n",
      "\n",
      "axes.scatter(y_train, train_residuals, 'r')\n",
      "axes.scatter(y_test, test_residuals, 'b')\n",
      "axes.set_xlabel('y_hat(log)')\n",
      "axes.set_ylabel('log(y)')\n",
      "axes.set_title('Residuals(log) vs. Log(Transvalue)');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1105866d0>"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Decision-Tree-based Feature Selection "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "tree_clf = ExtraTreesClassifier()\n",
      "X_new = tree_clf.fit(X_train[predictor], y_train).transform(X_train[predictor])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_importance = pd.DataFrame(zip(predictor, tree_clf.feature_importances_), \n",
      "                                  columns = ['feature', 'tree_based_feature_importance'])\n",
      "feature_importance.sort(['tree_based_feature_importance'], ascending = False, inplace=True)\n",
      "print \"********* Feautre Importance (tree-based selection) **************\"\n",
      "print feature_importance\n",
      "print \"******************************************************************\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "********* Feautre Importance (tree-based selection) **************\n",
        "              feature  tree_based_feature_importance\n",
        "3   lotsizesquarefeet                       0.466080\n",
        "2  finishedsquarefeet                       0.405319\n",
        "0         bathroomcnt                       0.073780\n",
        "1          bedroomcnt                       0.046413\n",
        "4            storycnt                       0.008408\n",
        "******************************************************************\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LinearRegression(fit_intercept=True, normalize=True)\n",
      "ridge = Ridge(alpha=88.862381627434075)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores_lr = cross_validation.cross_val_score(lr, X_train[predictor], y_train, cv=100)\n",
      "scores_ridge = cross_validation.cross_val_score(ridge, X_train[predictor], y_train, cv=100)\n",
      "scores = pd.DataFrame(zip(scores_lr, scores_ridge), columns=['LinearRegression', 'Ridge'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seaborn.boxplot(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x110569710>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSsf4f20bv32UULgAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1102b93d0>"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### GridSaerch for HyperParameter Tuning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "alphas = np.logspace(-4, 4, 40)\n",
      "ridge = Ridge()\n",
      "parameters = {\"alpha\":alphas}\n",
      "estimator = GridSearchCV(ridge, parameters)\n",
      "estimator.fit(X_train[predictor], y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 186,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'alpha': array([  1.00000e-04,   1.60372e-04,   2.57191e-04,   4.12463e-04,\n",
        "         6.61474e-04,   1.06082e-03,   1.70125e-03,   2.72833e-03,\n",
        "         4.37548e-03,   7.01704e-03,   1.12534e-02,   1.80472e-02,\n",
        "         2.89427e-02,   4.64159e-02,   7.44380e-02,   1.19378e-01,\n",
        "         1....,   9.42668e+02,   1.51178e+03,\n",
        "         2.42446e+03,   3.88816e+03,   6.23551e+03,   1.00000e+04])},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "Ridge(alpha=88.862381627434075, copy_X=True, fit_intercept=True,\n",
        "   max_iter=None, normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Pipeline\n",
      "Cacasding the opeartions:\n",
      "  a. feature selection\n",
      "  b. feature transformation\n",
      "  c. feature"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "from sklearn.datasets import samples_generator\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import f_regression\n",
      "from sklearn.pipeline import Pipeline\n",
      "X, y = samples_generator.make_classification(n_informative=5, n_redundant=0, random_state=42)\n",
      "\n",
      "def featureFilter(data, set_idx = 1):\n",
      "    \"\"\"\n",
      "    Subset data by keeping a collection of features\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    data: array-like, (n_samples, m_features)\n",
      "    features: array-like, (k_feautres, )\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    res: array-like\n",
      "    \"\"\"\n",
      "    features = ['bathroomcnt', 'bedroomcnt', 'finishedsquarefeet', 'lotsizesquarefeet', 'storycnt']\n",
      "    if set_idx == 1:\n",
      "        cols = [i for i in data.columns if i in features]\n",
      "    res = data[cols]\n",
      "    return res\n",
      "\n",
      "          \n",
      "pipline = Pipeline([('feature_filter', Imputer(missing_values='NaN', strategy='mean', axis=1)),\n",
      "                    ('ridge_regression', Ridge())])\n",
      "\n",
      "params = dict(feature_filter__set_idx = [1],\n",
      "              ridge_regression__alpha = np.logspace(-10, 10, 51))\n",
      "\n",
      "grid_search = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1)\n",
      "#grid_search.fit(X_train, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "featureFilter() takes at least 1 argument (0 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-199-0c4870c0fd95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m pipline = Pipeline([('feature_filter', featureFilter()),\n\u001b[0m\u001b[1;32m     28\u001b[0m                     ('ridge_regression', Ridge())])\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: featureFilter() takes at least 1 argument (0 given)"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_subset = featureFilter(X_train, predictor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "((2297, 5), (2297, 14))"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}